{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d1a4534-dc37-4536-8973-50a0f9027b67",
    "_uuid": "1b9b3f16dca00ef7fbcd940b4a169d8ccbe5adc7",
    "colab_type": "text",
    "collapsed": true,
    "id": "-OrBRfrGURKc"
   },
   "source": [
    "This tutorial is aimed at beginners, especially those who are both new to machine learning/data science as well as python. \n",
    "\n",
    "In this tutorial I would walk you through the process of building a predictive model, namely a decision tree. \n",
    "\n",
    "The pipeline consists of several steps:\n",
    "1. Exploratory Data Analysis (EDA) - understanding the data and the underlying interactions between the different variables\n",
    "2. Data Pre-processing - preparing the data for modelling\n",
    "3. Building the model\n",
    "4. Evaluating the performance of the model, and possibly fine-tune and tweak it if necessary\n",
    "\n",
    "The goal of the model is to predict whether a passenger survived the Titanic disaster, given their age, class and a few other features.\n",
    "\n",
    "Almost every line of code would be explained, so those who are more familiar with python (and especially with the numpy and pandas libraries) are welcome to skip the first parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5947836b-5cfc-49d2-bef3-901e9777e4bf",
    "_uuid": "d9b13d276c84df6ba7fc79b6a8ccf54e31d5b456",
    "colab_type": "text",
    "id": "vBLQM98aURKe"
   },
   "source": [
    "# Loading Libraries\n",
    "Not all python capabilities are loaded to your working environment by default (even if they exist and are installed on your computer), Therefore, we would need to import every library we are going to use. numpy and pandas are probably the most commonly used libraries. \n",
    "\n",
    "Numpy is requried whenever calculations are required (calculating means, medians, sqaure root, etc.).\n",
    "pandas is a great module for data processing and data frames. \n",
    "\n",
    "We can choose alias names to our modules for the sake of convenience (numpy --> np, pandas --> pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ef7fab81-4f99-4d2d-b9fb-18b056865432",
    "_uuid": "771840a8c53d43ca662e633ab4421cbee035e75c",
    "colab": {},
    "colab_type": "code",
    "id": "iWsGI9C0URKg"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9bcd144-73c4-4e19-ad9b-ad82f90d44d3",
    "_uuid": "63109d31e43047e42ee70a915e339a157d5b54db",
    "colab_type": "text",
    "id": "wijZ0f8HURKu"
   },
   "source": [
    "# Loading the data\n",
    "We would use the pandas module to read the files. using the \"read_csv\" function. the files format is.csv (similar to .xls)\n",
    "\n",
    "In the round brackets we have the path to where the data is saves i.e on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "57f44795-ca82-4e01-9595-7387851a6bce",
    "_uuid": "0c6d1e0ab1f4c92dfe988b4f5167c7a168cf8874",
    "colab": {},
    "colab_type": "code",
    "id": "GFecgnp-URKv"
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('https://raw.githubusercontent.com/dphi-official/First_ML_Model/master/titanic.csv')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0f85042b-370b-49ce-91e6-3af5a0f9f8db",
    "_uuid": "f2fefc8bc69d48f313e9b32f6ae664df0717e61d",
    "colab_type": "text",
    "id": "2sVNpOZZURK3"
   },
   "source": [
    "Now, let's examine our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "309ef627-5cf8-4061-ae28-6c4e31c9177b",
    "_uuid": "72401960ad124e524810776d963b8163adcf8750",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CHCzDCW0URK4",
    "outputId": "03495212-dcb6-41e0-eae7-ef399186d042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43003af4-572e-4348-acc1-d2fe29dedf62",
    "_uuid": "8319fd89c6621ee694f1b96cd58f54d5a3b80b15",
    "colab_type": "text",
    "id": "DL175E-sURLe"
   },
   "source": [
    "The \"head\" function displays the first 5 rows of the data frame. \n",
    "\n",
    "Let us explore the columns: \n",
    "* PassengerId - this is a just a generated Id\n",
    "* Pclass - which class did the passenger ride - first, second or third\n",
    "* Name - self explanatory\n",
    "* Sex - male or female\n",
    "* Age\n",
    "* SibSp - were the passenger's spouse or siblings  with them on the ship\n",
    "* Parch -  were the passenger's parents or children  with them on the ship\n",
    "* Ticket - ticket number\n",
    "* Fare - ticker price\n",
    "* Cabin\n",
    "* Embarked - port of embarkation\n",
    "* Survived - did the passenger  survive the sinking of the Titanic?\n",
    "\n",
    "**Note:** The whole goal is building a model that would predict the survival probability of a person, given their basic features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4cb2c715-0606-42eb-b553-e4f2296c4d46",
    "_uuid": "f11432f93e9a5787096309ff7b34f2367e8e1496",
    "colab_type": "text",
    "id": "0LGNCngKURLf"
   },
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "After loading the data, let us examine it. It is usually not recommended to throw all the data into a predictive model without first understanding the data. this would often help us improving our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "57e577a7-086d-48d8-be24-4dde7f974502",
    "_uuid": "9a0684a71ec848553d15d25f3a47e883cbfcb227",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_Yqcsdh7URLg",
    "outputId": "f7857422-4816-4d9d-e54b-4768dfae855b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of passangers in the training data... 891\n",
      "Number of passangers in the training data who survived... 342\n"
     ]
    }
   ],
   "source": [
    "print('Total number of passangers in the training data...', len(titanic))\n",
    "print('Number of passangers in the training data who survived...', len(titanic[titanic['Survived'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83033174-61d4-491f-a0e4-7cba203af975",
    "_uuid": "f7f1d663c50d06e9221e8d98921fcc906ebd7fec",
    "colab_type": "text",
    "id": "NdJ7-FxSURLl"
   },
   "source": [
    "The \"len\" function gives the length of whatever is the input, in that case our train data frame.\n",
    "\n",
    "We can access a specific column in a data frame by specifying its name in square brackets. we can also filter the values we are interested in with a condition.\n",
    "\n",
    "So the second line in the above cell should be understood as following:\n",
    "\"give me the length of the train data frame, if we only count the rows where the value of the \"Survived\" column id 1\"\n",
    "or, simply - \"give me the number of people (rows) who survived (\"survived = 1\")\n",
    "\n",
    "When we want to use the \"equals\" symbol in the context of a comparison\\condition statement, we use \"==\" instead of \"=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9007bd3b-a06f-474c-8503-46de42f1f890",
    "_uuid": "ed93f8e8d6a2ee152eaf9bce3d11e4dd3633db03",
    "colab_type": "text",
    "id": "5H5XKeMYURLm"
   },
   "source": [
    "Now, similarly, let's see what is the % of men and women who survived, and then by the same token with class and age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "d4349b9b-1d67-4870-be83-4e34dc81ea4f",
    "_uuid": "e3f18a91533f4795d604060d9c1107be7c903f06",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MtbEjdLUURLo",
    "outputId": "286b0cae-c369-41ac-dbfc-0be240dbc696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of men who survived 18.890814558058924\n",
      "% of women who survived 74.20382165605095\n"
     ]
    }
   ],
   "source": [
    "print('% of men who survived', 100*np.mean(titanic['Survived'][titanic['Sex'] == 'male']))\n",
    "print('% of women who survived', 100*np.mean(titanic['Survived'][titanic['Sex'] == 'female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fbf36afb-56a4-4f75-b12b-9fbf604f3ca8",
    "_uuid": "c91730bf52d86da39f669683ef59ad360d066692",
    "colab_type": "text",
    "id": "KChLIdYmURLs"
   },
   "source": [
    "Here we first use the numpy module, namely the \"mean\" function\".\n",
    "Let's try to understand the logics of the first line:\n",
    "* from left to right -   \"print 100 multiplied by the mean of the \"survived\" column but only where the sex is \"male\" \"\n",
    "* might be easier from right to left: \"let us only look at rows where the sex is \"male\", now from this reduced data frame let us only regard the \"survived\" column. let's take the mean of the column vales. and multiply by 100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_cell_guid": "0c44e371-eff7-4b01-b4bb-f4f0b9a834f6",
    "_uuid": "02f78a6c36eb6c4da68cc13c6278acfbe4b19fff",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fgUS7Kc_URLt",
    "outputId": "20f21837-ec8e-4cdb-c552-f35cc89b0aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of passengers who survived in first class 62.96296296296296\n",
      "% of passengers who survived in third class 24.236252545824847\n"
     ]
    }
   ],
   "source": [
    "print('% of passengers who survived in first class', 100*np.mean(titanic['Survived'][titanic['Pclass'] == 1]))\n",
    "print('% of passengers who survived in third class', 100*np.mean(titanic['Survived'][titanic['Pclass'] == 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "66c3b5b7-da10-49b2-8df0-a266313d4f5b",
    "_uuid": "4236cbe05e133e94f81c9753400b4818024797ea",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OKnVoFPRURLx",
    "outputId": "07b8b736-6168-4e4b-e341-503c93bfcbf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of children who survived 53.98230088495575\n",
      "% of adults who survived 38.26086956521739\n"
     ]
    }
   ],
   "source": [
    "print('% of children who survived', 100*np.mean(titanic['Survived'][titanic['Age'] < 18]))\n",
    "print('% of adults who survived', 100*np.mean(titanic['Survived'][titanic['Age'] > 18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1169b96a-5841-403f-998a-97550fec2533",
    "_uuid": "abedf7ec2812025e0e62105310939e7b808df396",
    "colab_type": "text",
    "id": "tPVsbM3cURL1"
   },
   "source": [
    "As we can see, at least in terms of survival statistics, the \"Titanic\" movie (spoiler alert) was an accurate representation of reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7df8c85b-e614-421f-9916-a8236d6ff60c",
    "_uuid": "991bfb4cd15db40a40ecc7f23dd4a5718563568d",
    "colab_type": "text",
    "id": "QYpOVKkDURL2"
   },
   "source": [
    "# Data Pre-processing\n",
    "## Non numeric features to numeric\n",
    "\n",
    "We are going to use a decision tree model. The model requires only numeric values, but one of our features is categorical: \"female\" or \"male\". this can easily be fixed by encoding this feature: \"male\" = 1, \"female\" = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "01cb9a3f-1a02-49ba-a4f8-922f49a5e8f3",
    "_uuid": "95a641fca86977b2965e3519d7aabc794b09b72b",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ry2C8CswURL2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nUnderstanding lambda functtion:\\nThe lambda function above is same as the user defined function below:\\n\\ndef fun(x):\\n    if x == 'male':\\n        return 1\\n    else:\\n    return 0\\n    \\n- x is the argument in both user defined function and lambda function (i.e. def func(x): is same as lambda x:)\\n- if x == 'male':\\n    return 1\\n    \\n    of user defined function is same as\\n    \\n    1 if x == 'male' of lambda function\\n    \\n    The only difference here is - in lambda function the first return statement is placed before the condition and no 'return'\\n    keyword is used.\\n    \\n- After if statement the else part is similar in both cases the only difference is no 'return' keyword used.\\n[return keyword is not used in lambda function][lambda function is used only for small set of statements]\\n\\nA youtube video on lambda function: https://www.youtube.com/watch?v=hYzwCsKGRrg\\n\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['Sex'] = titanic['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "\"\"\"\n",
    "Understanding lambda functtion:\n",
    "The lambda function above is same as the user defined function below:\n",
    "\n",
    "def fun(x):\n",
    "    if x == 'male':\n",
    "        return 1\n",
    "    else:\n",
    "    return 0\n",
    "    \n",
    "- x is the argument in both user defined function and lambda function (i.e. def func(x): is same as lambda x:)\n",
    "- if x == 'male':\n",
    "    return 1\n",
    "    \n",
    "    of user defined function is same as\n",
    "    \n",
    "    1 if x == 'male' of lambda function\n",
    "    \n",
    "    The only difference here is - in lambda function the first return statement is placed before the condition and no 'return'\n",
    "    keyword is used.\n",
    "    \n",
    "- After if statement the else part is similar in both cases the only difference is no 'return' keyword used.\n",
    "[return keyword is not used in lambda function][lambda function is used only for small set of statements]\n",
    "\n",
    "A youtube video on lambda function: https://www.youtube.com/watch?v=hYzwCsKGRrg\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0fff96d9-878a-4665-8ee2-e239828849f0",
    "_uuid": "98fab53c6fb07de6e0a3b0ec7544889e7791c9bb",
    "colab_type": "text",
    "id": "nRvfePehURL6"
   },
   "source": [
    "The \"apply\" means \"do that for each value in the column\". the statement in the brackets should be read as following :\"for every value in the column (\"lambda x:\") if it's a male then replace with 1, otherwise replace with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "96d224c1-072e-4622-bc86-32be35bdab84",
    "_uuid": "948dc51e6937347b06cc4ac38c91376990cfc6e6",
    "colab_type": "text",
    "id": "kjRBTidEURL7"
   },
   "source": [
    "## Missing Values\n",
    "Another common problem which has to be addressed is missing values. We can simply delete rows with missing values, but usually we would 'want to take advantage of as many data points as possible. Replacing missing values with zeros would not be a good idea - as age 0 or price 0 have actual meanings and that would change our data.\n",
    "\n",
    "Therefore a good replacement value would be something that doesn't affect the data too much, such as the median or mean. the \"fillna\" function replaces every NaN (not a number) entry with the given input (the mean of the column in our case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "0f385258-9f0e-49d7-b1dd-1cbfe21b9e26",
    "_uuid": "73940633ac23734e029fabdaced15a2929e5d215",
    "colab": {},
    "colab_type": "code",
    "id": "ta_o3HxPURL8"
   },
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic['Age'].fillna(np.mean(titanic['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at frequency of each values in 'Embarked'\n",
    "titanic.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing values of a categorical variable with mode. The below mentioned mentioned code is not an ideal way\n",
    "to fill missing values of categorical, we shall explain best practices in future sessions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use fillna() function to fill the missing values as discussed in the pandas session / notebook.\n",
    "titanic.Embarked.fillna(value='S', axis = 0, inplace = True) #rowwise input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d997e088-dad3-42cd-90b4-a75168ce172e",
    "_uuid": "47dab29235a85fffc0b5b12084ef3b93d11e934c",
    "colab_type": "text",
    "id": "3Xh59YuqURMA"
   },
   "source": [
    "## Omit irrelevant columns\n",
    "Let us only take the columns we find relevant. ID columns are never relevant (or at least should not be, if the data was sampled randomly). As our model is very simple, let us also omit the Ticket number, Cabin, ID and Name although more sophisticated models can definitely take advantage of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "834704b8-6ab6-4dcd-af37-6c488cddbcbb",
    "_uuid": "036f0f134f69c3324a2fc3d2cad92abd22689ed5",
    "colab": {},
    "colab_type": "code",
    "id": "RSAB6pyhURMA"
   },
   "outputs": [],
   "source": [
    "titanic = titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d4fc080-d028-48cb-801b-a994f740b69e",
    "_uuid": "2686da3bb9d127a63abc241d6575bcc1b7d9f0ee",
    "colab_type": "text",
    "id": "EF0Qw3OPURME"
   },
   "source": [
    "## Separating input variables (X) and target variable (y)\n",
    "Y has the labels, our answers column. X is all the rest of the data - the features, without the labels (The survived column). This sepration would hoepfully be clearer in a few cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "94d20915-240a-42f1-9326-d47e0ddd1641",
    "_uuid": "577bccd13d936e4efbf9aa6b744d6b56a73fc35b",
    "colab": {},
    "colab_type": "code",
    "id": "Er9E_NgnURMF"
   },
   "outputs": [],
   "source": [
    "X = titanic.drop('Survived', axis = 1)\n",
    "y = titanic['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6e39357-af7d-43e7-8111-3eff852cd61c",
    "_uuid": "63593682627a3861c6f1a8c056ea949e1f53b14b",
    "colab_type": "text",
    "id": "fYtyOrd-URMK"
   },
   "source": [
    "As explained above, X now has the train data without the \"Survived\" column (this is acheived with the \"drop\" function). Y, on the other hand, has only the \"Survived\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "053286f6-8e2c-4238-9690-7db3471caec4",
    "_uuid": "e7b53cc7fccbe98ed6673fe1643116daa74cb486",
    "colab_type": "text",
    "id": "Ns3dWPYUURML"
   },
   "source": [
    "# Train and Test Split\n",
    "\n",
    "We have our training data, and we have our test data. but in order to evaluate our model we need to split the training dataset into a train dataset and an evaluation dataset (validation). The validation data would be used to evaluate the model, while the training data would be used to train the data. \n",
    "\n",
    "To do that, we can use the function \"train_test_split\" from the sklearn module. the sklean module is probably the most commonly used library in most simple machine learning tasks (this does not include deep learning where other libraries can be more popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "ac03adee-9bdf-49ee-a248-0fa13ccd7dd2",
    "_uuid": "f2f9fbda9a72c354f36dd792b0839b2f428ed6c7",
    "colab": {},
    "colab_type": "code",
    "id": "EU6clulxURMM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc719fe3-3b5f-476e-bdca-6441810fb4ac",
    "_uuid": "cc39ee250eff5dccacbbb765f5c30950ee96bd4c",
    "colab_type": "text",
    "id": "lSM8rC1NURMR"
   },
   "source": [
    "## Building ML Model\n",
    "Now we are finally ready, and we can train the model.\n",
    "\n",
    "First, we need to import our model - A decision tree classifier (again, using the sklearn library).\n",
    "\n",
    "Then we would feed the model both with the data (X_train) and the answers for that data (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "06268f0c-2305-44b7-99a1-15eed66fa237",
    "_uuid": "b419cbe623724fe86da1ff85df016982dae245eb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "v3jmucB5URMS",
    "outputId": "27167820-ec8d-4b5a-e5b9-b488fc271e2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e780a67c-5033-4a78-a1a6-be14ee031271",
    "_uuid": "ce09fa783a379952f5eb6ca9d9b3e2850ea6ee01",
    "colab_type": "text",
    "id": "0jquUG30URMX"
   },
   "source": [
    "The training happens in the third line (the \"fit\" function). During the training, the algorithm is trying to build the optimal decision tree. The way it works is very similar to the game \"21 Questions\". In the game we always start with general questions that give the best partition of the data (\"is the character you are thinking of a male? are them alive?\" etc.). It tries to acheive the best score on the training data - that is, building a model that would predict the survival outcome of as many passengers as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "76e24a80-f193-4608-b5f7-17d4c7b75978",
    "_uuid": "2e6c62ac07211ae6c35f0c53bb0fb055baf5620e",
    "colab_type": "text",
    "id": "CLT2AQj3URMX"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "672995f2-2213-4c8c-8c53-aefbb3635a8d",
    "_uuid": "fbc2a8d277e24b0dcf41828804805ecc911645d5",
    "colab_type": "text",
    "id": "5eg4hreYURMY"
   },
   "source": [
    "Now we have a model. Let's evaulate it with using the accuracy_score function. This output of the function is the number of right answers (passengers survival/death was predicted correctly) divided by the total number of passengers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\chanukya\\anaconda3\\lib\\site-packages (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "3a444611-070d-43d5-ab4e-67d883eee932",
    "_uuid": "dc7ada4a264300beb9c847df2af2691288b423f3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lpriWPY-URMZ",
    "outputId": "4760b625-3685-4310-b4d5-5cfa91b8b698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy... 0.9798657718120806\n",
      "Validation accuracy 0.7423728813559322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Training accuracy...', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Validation accuracy', accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4ddf0d2-5821-444a-952a-7625c7073d47",
    "_uuid": "22f9924113204b10a04cef929da3869fc792a037",
    "colab_type": "text",
    "id": "isg-TZ2zURMd"
   },
   "source": [
    "The accuracy function compares between the actual results (our ground truth - y_train or y_test) with the prediction of the model (given by \"classifier.predict(X_train)\" or \"classifier.predict(X_test)\" respectrively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aaed3efc-701f-4356-98fd-8f5bc16b5fa9",
    "_uuid": "bccc9b6063252dd80f10cd46c5d3dc566b449513",
    "colab_type": "text",
    "id": "nQaQhGnsURMd"
   },
   "source": [
    "The large difference between the training score and the validation score suggets that our model **overfits**. That is, instead of leraning general rules that can be applied on unseen data, it does something that is more similar to memorize the training data. So our model performs really well on the training data (98% accuracy) but not remotely as well on the validation data.\n",
    "\n",
    "It is clear once we plot the tree. the next bulk of code would not be explained and can be regarded as a useful magic that plots decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    136\u001b[0m         out = backend.pipe(self._engine, format, data,\n\u001b[0;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                            quiet=quiet)\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \"\"\"\n\u001b[0;32m    243\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x200265d8288>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import graphviz\n",
    "dot_data = export_graphviz(model, out_file=None, \n",
    "                    feature_names=X_test.columns.values,  \n",
    "                      class_names=['No', 'Yes'],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1KpDh2YAeVyY",
    "outputId": "a34d0f4c-b85c-4286-c12e-df9f5a1f59e7"
   },
   "outputs": [],
   "source": [
    "# The decision tree generated here is too large, so it is difficult to show here in the notebook locally\n",
    "export_graphviz(model, 'dtree1.tree',feature_names=X.columns)    # dtree1.tree will be saved in local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![My Title](https://dphi.tech/wp-content/uploads/2020/06/tree1-1024x515.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f10368a-1215-4630-8568-6bb923fa552d",
    "_uuid": "d19b0b949aa14da0a8048f61a2f4bfa065ebcb93",
    "colab_type": "text",
    "id": "oS6Us7mdURMj"
   },
   "source": [
    "This is a very complex model, and if you zoom in you would see that in many leaves we have only 1 sample. this means that the model learned many complex rules to memorize the survival or death of each passenger in the training data. \n",
    "\n",
    "Let's take Mr. Owen Harris\t(the first row of the training data),  having such a complex model is similar to having a rule that says that if a passenger is in class 3, and is a male, and his age is more than 21, and his age is less than 23, and his fare is more than 7, and his fare is less than 8, and he has a sibling/spouse on board with him but no parents/children, then he would not survive. But this is obviously a rule that was tailor made to Mr Harris, and is equivalent to simply saying \"Mr Harris did not survive\", a rule that cannot be generalized to new unseen passengers who are not Mr Harris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "544c0c07-a9f7-4ae1-b791-bddd8da914f7",
    "_uuid": "837348554bf67756e1ec44909d9dc9e9c7a05da6",
    "colab_type": "text",
    "id": "-TICPH0rURMk"
   },
   "source": [
    "## Improve the model\n",
    "We can reduce overfitting by limiting the number of \"questions\" that the model is allowed to ask. as each node in the tree is a question, by limiting the depth of the tree we can limit the number of questions. So let us again create an instance of a decision tree, but this one cannot produce trees deeper than 3 (3 questions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "74b0b499-fa8a-4e7e-946b-917d94f67662",
    "_uuid": "0dab58e1a011dba69fe134ffa913e77f35fe0694",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "L9R6caKlURMl",
    "outputId": "aa9d699a-384e-4988-8b52-bf16cfd7fdf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_improved = DecisionTreeClassifier(max_depth = 3)\n",
    "model_improved.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "0ac6a11d-ac2b-429c-8458-5eb3a81bcdb5",
    "_uuid": "c9815fca98372719f96c6deb3bb61afb1aefd0d3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BoDHSUX6URMp",
    "outputId": "ca62e014-2af9-4f87-f6f4-7e1c7cbddc6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score... 0.8238255033557047\n",
      "test score... 0.8203389830508474\n"
     ]
    }
   ],
   "source": [
    "print('train score...' , accuracy_score(y_train, model_improved.predict(X_train)))\n",
    "print('test score...', accuracy_score(y_test, model_improved.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9cbd950-63b1-4fec-b0e7-4cb3efaf1dc6",
    "_uuid": "7ac4d60a2f513a2d52e053cf9955afe2576cd06a",
    "colab_type": "text",
    "id": "pzB3RipEURMv"
   },
   "source": [
    "We can see that while the train score went down, the test score has improved and it is now almost as high as the train score. This means that the model does not overfit as badly anymore. 82% accuracy with such a simple model is quite impressive in my opinion. \n",
    "\n",
    "Let's visualize the tree again using the same code snippet from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(model_improved, 'dtree2.tree',feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![My Title](https://dphi.tech/wp-content/uploads/2020/06/tree2-1024x394.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10de6c02-59d4-48e1-85ed-d0c81cb22916",
    "_uuid": "244ac1cc928275a98260802d497760e2be705274",
    "colab_type": "text",
    "collapsed": true,
    "id": "abD678avURM2"
   },
   "source": [
    "The training is the process of finding the most important features, and then use them to split the data. The training algorithm found that the most important features is the Sex. secondly, the class for females, and age for males. the bluer the block is, the higher the survival rate is, and opoositely with browner blocker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate graph, use this url: http://www.webgraphviz.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMSszk8peVyw"
   },
   "source": [
    "The reference original reference link of this tutorial can be found here: https://www.kaggle.com/drgilermo/a-tutorial-for-complete-beginners"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_with_titanic_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
